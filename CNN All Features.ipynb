{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Use this if you need to create images of the same type & size###\n",
    "##This section is NOT needed to run the model everytime\n",
    "\n",
    "#Path of directory\n",
    "train_path = \"More Fake/\"\n",
    "dirs = os.listdir( path1 )\n",
    "\n",
    "#Resizing images to be 200x200 px\n",
    "def resize_img(path):\n",
    "    dirs2 = os.listdir(path)\n",
    "    for item in dirs2:\n",
    "        if item == '.DS_Store':\n",
    "            continue\n",
    "        img = Image.open(path+item)\n",
    "        f, e = os.path.splitext(path+item)\n",
    "        imResize = img.resize((200, 200), Image.ANTIALIAS)\n",
    "        imResize.save(f + 'new_image.png', 'PNG')\n",
    "\n",
    "#Running the function\n",
    "resize_img(path1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating paths to the training and testing data\n",
    "train_data_dir = 'Feature & Real Train'\n",
    "validation_data_dir = 'Feature & Real Test'\n",
    "\n",
    "train_real_dir = 'Feature & Real Train'\n",
    "train_fake_dir = 'Feature & Real Train'\n",
    "\n",
    "test_real_dir = 'Feature & Real Test'\n",
    "test_fake_dir = 'Feature & Real Test'\n",
    "\n",
    "#counting files in directory\n",
    "nb_train_samples = len(next(os.walk(train_real_dir))[2] + next(os.walk(train_fake_dir))[2]) - 2\n",
    "nb_validation_samples = len(next(os.walk(test_real_dir))[2] + next(os.walk(test_fake_dir))[2]) - 2\n",
    "\n",
    "#Establishing # of epochs and batch size\n",
    "#I'm using limited epochs and a smaller batch size due to limited computing power\n",
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stating img dimensions & data format for the model and image generation\n",
    "img_width, img_height = 200, 200\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating CNN\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), input_shape = input_shape),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Conv2D(32, (3,3)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "    #keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3,3)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Conv2D(64, (3,3)),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "    #keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(14),\n",
    "    #Using softmax since categorial & output nodes > 2\n",
    "    keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 790 images belonging to 14 classes.\n",
      "Found 129 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "#augmentation configuration used for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#augmentation configuration used for testing:\n",
    "#rescaling the images\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 7 steps\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 208s 5s/step - loss: 0.2713 - accuracy: 0.9221 - val_loss: 0.2636 - val_accuracy: 0.9286\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 175s 4s/step - loss: 0.2018 - accuracy: 0.9324 - val_loss: 0.2577 - val_accuracy: 0.9291\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 167s 4s/step - loss: 0.1714 - accuracy: 0.9373 - val_loss: 0.2950 - val_accuracy: 0.9175\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 175s 4s/step - loss: 0.1553 - accuracy: 0.9434 - val_loss: 0.2586 - val_accuracy: 0.9286\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 167s 4s/step - loss: 0.1362 - accuracy: 0.9457 - val_loss: 0.3182 - val_accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1275980d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-43-5d51e5b4db04>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31816257749285015, 0.9130675]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = len(validation_generator)\n",
    "model.evaluate_generator(validation_generator, steps=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "###NOTES###\n",
    "\n",
    "##5 epochs with batch size = 20\n",
    "## 94.8% accuracy\n",
    "##test set produced 91% accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
